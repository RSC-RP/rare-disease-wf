//working directory for temporary/intermediate files produced in the workflow processes
workDir = "$HOME/temp"

// parameters
params {
    // PBS parameters
    //queue = 'sceaq'
    queue = 'paidq'
    project = '207f23bf-acb6-4835-8bfe-142436acb58c'

    // VCF to start with
    //vcf = "/gpfs/shared_data/demo_data/rare-disease-wf/Ashkenazim_GIAB.glnexus.bcf" // WES, full genome, on single trio
    vcf = "testdata/Ashkenazim_GIAB_small.glnexus.vcf" // WES on single trio, subsetted to a tiny fraction of the genome
    chromnames = 'g1k' // Format for chromosome names input. g1k = 1000 Genomes. Alternatives are ensembl and ucsc. Use ucsc if chromosome names start with 'chr'
    sort = false // Whether to sort the VCF before processing.

    // Pedigree file
    ped = "testdata/GIAB_pedigree.txt"
    trios_present = true // Set to false if pedigree contains no trios (duos only).

    // Sample metadata for UMAP plots
    metadata_tab = "testdata/GIAB_demographics.txt"
    metadata_columns = "affected,batch,favorite_animal"

    // Incidental findings
    do_incidental = true
    incidental_samples = "testdata/GIAB_incidental.txt"

    // Should annotated VCF be exported before filtering?
    export_prefilt = false

    // BAMs and variant calling
    sample_bams = "testdata/GIAB_samples_small.csv"
    deepvar_model = "WES" // Should be WGS or WES.
    cohort_name = "Ashkenazim_GIAB_small"
    //make_examples_nshards = 32 // Use 32 for full genome.
    make_examples_nshards = 4 // Use this many for tiny example dataset.
    test_bams = true // change to false to run the entire genome.  True runs a tiny example piece.
    // fasta_bams should be the reference genome that was used for alignment of the BAMs. Check BAM header if unsure.
    fasta_bams = "/gpfs/shared_data/references/Homo_sapiens/Ensembl/GRCh37/Sequence/WholeGenomeFasta/Homo_sapiens.GRCh37.dna.primary_assembly.fa"

    // output
    outdir = "results"

    // Ensembl reference - change if using hg38
    fasta_ensembl = "/gpfs/shared_data/references/Homo_sapiens/Ensembl/GRCh37/Sequence/WholeGenomeFasta/Homo_sapiens.GRCh37.dna.primary_assembly.fa"
    gff_ensembl = "/gpfs/shared_data/references/Homo_sapiens/Ensembl/GRCh37/Annotation/Genes/Homo_sapiens.GRCh37.87.gff3"

    // Directory for cached snpEff database
    snpEff_dir = "/gpfs/shared_data/snpEff/Ensembl"

    // Gnotation and selfchain files for slivar
    slivar_zip = "/gpfs/shared_data/Slivar/gnomad.hg37.zip"
    slivar_selfchain = "/gpfs/shared_data/Slivar/selfchain-LCR.hg19.bed"

    // AnnoVar database files
    annovar_db = "/gpfs/shared_data/AnnoVar/humandb"
    annovar_buildver = "hg19"

    // MVP pathogenicity prediction score table
    mvp_tab = "/gpfs/shared_data/MVP/MVP_score_hg19.txt"

    // Slivar filtering parameters
    maf_recessive = "0.001"
    maf_dominant = "0.00002"
    maf_denovo = "0.001"
    comphet_nhomalt = "10"

    // Pathogenicity filtering parameters
    mvp_thresh = 0.9
    cadd_thresh = 7
    dann_thresh = 0.999
    gerp_thresh = 5.5

    // UMAP parameters
    umap_seed = 3334444
    umap_min_call_rate = 0.95
    umap_n_exons = 5000
    umap_n_pcs = 50

    // File used if UCSC chromosome names need to be changed to Ensembl
    chrom_convert = 'chrom_conversion.txt'

    // gnomAD VCF
    // Not used in the main repo, but can be used with BCFTOOLS_ANNOTATE_INFO to add allele frequencies.
    gnomad_vcf = '/gpfs/shared_data/gnomAD/gnomad.genomes.r2.1.1.sites.vcf.bgz'

    // Params for preprocessvcf which may be deprecated
    fasta38ucsc = "/gpfs/shared_data/references/Homo_sapiens/UCSC/hg38/Sequence/WholeGenomeFasta/hg38.p13.fa.gz"
    fasta19ucsc = "/gpfs/shared_data/references/Homo_sapiens/UCSC/hg19/Sequence/WholeGenomeFasta/hg19.fa"
    do_liftover = true // Set to true if VCF is hg19, and false if it is hg38.
    picard_max_records_in_ram = 500000 // lower if liftover is running out of memory
    picard_memory_gb = 15 // memory available for liftover, in Gb
}

//Create profiles to easily switch between the different process executors and platforms.
params.enable_conda=false //Using the profile "PBS_conda" will set this to true, otherwise it should be false
profiles {
    //For running on an interactive session on cybertron with singularity module loaded
    local_singularity {
        process.executor = 'local'
        singularity.enabled = true
        process.beforeScript = 'module load singularity'
    }
    //For executing the jobs on the HPC cluster with singularity containers
    PBS_singularity {
        process.executor = 'pbspro'
        process.queue = "${params.queue}"
        process.clusterOptions = "-P ${params.project}"
        //process.clusterOptions = "-P \$(project code ${params.project})" //renders correctly in command.run script but scheduler won't accept it.
        process.beforeScript = 'module load singularity' //parameterize the module version with params.SINGULARITY in main_run.sh
        singularity.enabled = true //need some logic here to switch to false if conda used
    }
    //For executing the jobs on the HPC cluster with apptainer containers
    PBS_apptainer {
        process.executor = 'pbspro'
        process.queue = "${params.queue}"
        process.clusterOptions = "-P ${params.project}"
        process.beforeScript = 'module load apptainer'
        apptainer.enabled = true
    }
    //For executing the jobs on the HPC cluster with conda environments.
    PBS_conda {
        process.executor = 'pbspro'
        process.queue = "${params.queue}"
        process.clusterOptions = "-P ${params.project}"
        params.enable_conda = true
    }
    //For running interactively on local macbook with docker installed.
    local_docker {
        process.executor = 'local'
        docker.enabled = true
    }
}

//Configs for singularity containers on cybertron
singularity {
    autoMounts = true
    cacheDir = "$HOME/singularity"
    runOptions = '--containall --no-home'
}

apptainer {
    autoMounts = true
    cacheDir = "$HOME/apptainer"
    runOptions = '--containall --no-home'
}

process {
    errorStrategy = { task.exitStatus in [1,143,137,104,134,139,250] ? 'retry' : 'terminate' }
    cache = 'lenient'
    maxRetries = 0
    withName:'SNPEFF'{
        cpus = 1
        memory = 8.GB
    }
    withName:'MVP_ANNO'{
        cpus = 1
        memory = 16.GB
    }
    withName:'SPLIT' {
        cpus = 2
        memory = 4.GB
    }
    withName:'SNPSIFT_ANNOTATE'{
        cpus = 1
        memory = 8.GB
    }
    withName:'FILTER_PATHOGENIC'{
        cpus = 1
        memory = 16.GB
    }
    withName:'MAKE_EXAMPLES_TRIO' {
        cpus = params.make_examples_nshards
        memory = 64.GB
    }
    withName:'CALL_VARIANTS_TRIO' {
        // Special settings to use GPU.  Assumes PBS_singularity.
        clusterOptions = "-l select=1:ncpus=4:mem=51200mb:ngpus=1 -P ${params.project}"
        singularity.runOptions = '--containall --no-home --nv'
    }
    withName:'POSTPROCESS_VARIANTS' {
        cpus = 1
        memory = 32.GB
    }
    withName:'GLNEXUS' {
        cpus = 16
        memory = 128.GB
    }
}
